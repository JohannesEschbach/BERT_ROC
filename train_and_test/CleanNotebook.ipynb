{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StoriesSemantics.ipynb","provenance":[{"file_id":"https://github.com/JohannesEschbach/BERT_ROC/blob/johannes/runBertForNextSentencePrediction.ipynb","timestamp":1615753750868}],"collapsed_sections":["VGUHTlObOfPr","EJO2HeysOmYx","2EDcfMlhItBd","x1-E16-F984x","YROdTgL0IM3U","8CkrBmqpBUQi","8faj36chTaL_"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"48bc834a572b4caea553ebdf503f2805":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_47015140fe974c8b93c4892c21f8443a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_04e3744ceec747e0991dd1b983e9c182","IPY_MODEL_aec79fd6a7db4eeab3da94a9b9deaee1"]}},"47015140fe974c8b93c4892c21f8443a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04e3744ceec747e0991dd1b983e9c182":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e50a9eeaa40f44489e836fecde3f9488","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5058110ecc7f4c8aa4503ea66e4b84f3"}},"aec79fd6a7db4eeab3da94a9b9deaee1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0ad911e432742fcb4d1f07f04e164cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 741kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_36e5bde718294941a5af2777e868c15d"}},"e50a9eeaa40f44489e836fecde3f9488":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5058110ecc7f4c8aa4503ea66e4b84f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0ad911e432742fcb4d1f07f04e164cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"36e5bde718294941a5af2777e868c15d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e7419e89da14f56aa4b139f0b166aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e2eb3fa60b24fec958cf9a999d7b0de","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e508a5b6815e4c24bdcf4159ed0a1cbc","IPY_MODEL_fd0742d6d3654dd2a2c9cc41a0e14c3f"]}},"0e2eb3fa60b24fec958cf9a999d7b0de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e508a5b6815e4c24bdcf4159ed0a1cbc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_139af509727244b590e605cb5ff3072b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4648acf5c5f446509474d055371d2885"}},"fd0742d6d3654dd2a2c9cc41a0e14c3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f1b9a86fe0d845a08304399f63d8f2d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 159B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20caba27808345d48e64ffafac8af693"}},"139af509727244b590e605cb5ff3072b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4648acf5c5f446509474d055371d2885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1b9a86fe0d845a08304399f63d8f2d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20caba27808345d48e64ffafac8af693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92254b324ed64720aeafc20406227b52":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a53f074e27d4cd685ede72dc713f195","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e936f0da5184904b98cbe53453be9cd","IPY_MODEL_19315383b0a74f7caaf801f12302b1eb"]}},"0a53f074e27d4cd685ede72dc713f195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e936f0da5184904b98cbe53453be9cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a62c79e1b8114feebc28639702988e5d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1a628c8050a4eb8b4bda16af0d377d9"}},"19315383b0a74f7caaf801f12302b1eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5e0391ae83b74f7bb033ea241dce1dcd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 5.37MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20840f2e8dc5442ca3da6ce181648c61"}},"a62c79e1b8114feebc28639702988e5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1a628c8050a4eb8b4bda16af0d377d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e0391ae83b74f7bb033ea241dce1dcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20840f2e8dc5442ca3da6ce181648c61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43f11a89945548299b1a1fe70cdd02b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9a66b09c8fac4847b8fe6dd9264063b3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bcfb4225c10a4584914f48bb464fe673","IPY_MODEL_eb58485470ef458c9467b27feff065f1"]}},"9a66b09c8fac4847b8fe6dd9264063b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcfb4225c10a4584914f48bb464fe673":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fcce2d5ba4464f7e819abaf14983b0c0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":434,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":434,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e48d9030d6884af78970b1f76b6363d4"}},"eb58485470ef458c9467b27feff065f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3084e1527db24e6a88197360d2c658a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 434/434 [00:00&lt;00:00, 4.24kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3f9f2cd1abb54d5cbf72f888b101f395"}},"fcce2d5ba4464f7e819abaf14983b0c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e48d9030d6884af78970b1f76b6363d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3084e1527db24e6a88197360d2c658a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3f9f2cd1abb54d5cbf72f888b101f395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c53c30ca6eb549cebf68975752ed7df9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2d83a898e1bf4f948bf5129e4ebea6de","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dbc603d6b2ae42a5adcece4d6c2ad88a","IPY_MODEL_249c5f6ddc9e41a2972e27b4e67e8aac"]}},"2d83a898e1bf4f948bf5129e4ebea6de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbc603d6b2ae42a5adcece4d6c2ad88a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dfb189e448634b779d5371273238b634","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1345000548,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1345000548,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f88b0edc3c94a5fbf579d42846963f1"}},"249c5f6ddc9e41a2972e27b4e67e8aac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4036525e2ec405ab2df8086fbe11db0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.35G/1.35G [00:26&lt;00:00, 51.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7fac0e91299d410aaf340e84c8949912"}},"dfb189e448634b779d5371273238b634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5f88b0edc3c94a5fbf579d42846963f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4036525e2ec405ab2df8086fbe11db0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7fac0e91299d410aaf340e84c8949912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"VGUHTlObOfPr"},"source":["# Headers and Global Variables"]},{"cell_type":"code","metadata":{"id":"D4MUY1yyup2m","executionInfo":{"status":"ok","timestamp":1617103773279,"user_tz":-120,"elapsed":6425,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["import csv\n","import torch\n","from torch.nn.functional import softmax\n","from torch.nn.functional import relu\n","from transformers import BertForNextSentencePrediction, BertTokenizer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","import matplotlib\n","from matplotlib import pyplot as plt\n","from matplotlib import pyplot as plt\n","from IPython.display import display, HTML\n","\n","import os\n","import sys\n","from pathlib import Path\n","\n","project_path = Path(os.path.dirname(os.path.realpath(sys.argv[0]))).parent\n","modelpath = str(project_path.joinpath('models')) + \"/\"\n","datapath = str(project_path.joinpath('datasets')) + \"/\"\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","CLOZE_MODEL = 'bertfornsp_clozeonly_finetuned'\n","ROC_MODEL = 'bertfornsp_roc_finetuned'\n","# underlying pretrained LM\n","BASE_MODEL = 'bert-large-uncased-whole-word-masking'\n","\n","BATCH_SIZE = 12\n","WARMUP_EPOCHS = 1\n","TRAIN_EPOCHS = 10\n","LAST_EPOCH = -1"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EJO2HeysOmYx"},"source":["# Datasets"]},{"cell_type":"code","metadata":{"id":"fdWgHZQtxHi8","executionInfo":{"status":"ok","timestamp":1617103773280,"user_tz":-120,"elapsed":4725,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["class RocStories(torch.utils.data.Dataset):\n","    \"\"\"\n","    Class prepares roc_stories.csv for training\n","    \"\"\"\n","    def __init__(self, short = False):\n","    \"\"\"    \n","    :param short: When true, crop the data at 5000th rows\n","    \"\"\"\n","        dataset = []       \n","        with open(datapath + 'roc_stories.csv', \n","                  'r', encoding='utf-8') as d:\n","            \n","            reader = csv.reader(d, quotechar='\"', delimiter=',',\n","                                quoting=csv.QUOTE_ALL, skipinitialspace=True)                \n","            for line in reader:\n","                dataset.append(line)  \n","\n","        self.data = []\n","        self.labels = []\n","\n","        stories = []\n","        endings = []\n","        for i, sample in enumerate(dataset):\n","            if short == True:\n","                if i >= 5000: break           \n","            start = \" \".join(sample[2:-1])\n","            stories.append(start)            \n","            end = sample[-1]                        \n","            endings.append(end)\n","\n","        from random import shuffle\n","        wrong_endings = endings.copy()\n","        shuffle(wrong_endings)\n","\n","        assert len(stories) == len(endings)\n","        for i, story in enumerate(stories):\n","            \n","            #True Ending\n","            self.data.append([story, endings[i]])\n","            self.labels.append(0)\n","\n","            #Wrong Ending\n","            self.data.append([story, wrong_endings[i]])\n","            self.labels.append(1)\n","\n","    def __getitem__(self, idx):\n","        X = self.data[idx]\n","        y = self.labels[idx]        \n","        return X, y\n","\n","    def __len__(self):\n","        assert len(self.data) == len(self.labels)\n","        return len(self.labels)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6zAL8cquyF1","executionInfo":{"status":"ok","timestamp":1617103773281,"user_tz":-120,"elapsed":4724,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["class ClozeTest(torch.utils.data.Dataset):\n","    \"\"\"\n","    Class prepares csv file for binary testing and training\n","    \"\"\"\n","    def __init__(self, dev=True, hypothesis_only=False, file = None):\n","        \"\"\"\n","        :param hypothesis_only: Replaces story with empty string. Only Keeps endings as they are.\n","        :param dev: if dev=True, load dev set for testing, otherwise training set\n","        :param file: csv file to load the data from\n","        \"\"\"\n","\n","        dataset = []\n","\n","        # if dev=True, we load the dev set for testing\n","        dir = \"\"\n","        \n","        if file is None:\n","          if dev:\n","              dir = datapath + 'cloze_test.csv'\n","          else:\n","              dir = datapath + 'cloze_train.csv'\n","        else: dir = datapath + file\n","\n","        with open(dir, 'r', encoding='utf-8') as d:\n","            reader = csv.reader(d, quotechar='\"', delimiter=',', \n","                                quoting=csv.QUOTE_ALL, skipinitialspace=True)                \n","            for line in reader:\n","                dataset.append(line) \n","            dataset.pop(0)\n","\n","        self.data = []\n","        self.labels = []\n","\n","        for sample in dataset:\n","            \n","            start = \" \".join(sample[1:-3])\n","            if hypothesis_only: start = \"\"\n","            end1 = sample[-3]\n","            end2 = sample[-2]\n","            right_ending = sample[-1]\n","\n","            self.data.append([start, end1])\n","            self.labels.append(0 if \"1\" == right_ending else 1)\n","\n","            self.data.append([start, end2])\n","            self.labels.append(0 if \"2\" == right_ending else 1)\n","\n","    def __getitem__(self, idx):\n","        X = self.data[idx]\n","        y = self.labels[idx]        \n","        return X, y\n","\n","    def __len__(self):\n","        assert len(self.data) == len(self.labels)\n","        return len(self.labels)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyVAy1RKYMTR","executionInfo":{"status":"ok","timestamp":1617103773282,"user_tz":-120,"elapsed":4723,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["class ClozeTest_MC(torch.utils.data.Dataset):\n","    \"\"\"\n","    Class prepares csv file for choice based testing and training\n","    \"\"\"\n","    def __init__(self, dev=True,  hypothesis_only=False, file = None):\n","        \"\"\"\n","        :param hypothesis_only: Replaces story with empty string. Only Keeps endings as they are.\n","        :param dev: if dev=True, load dev set for testing, otherwise training set\n","        :param file: csv file to load the data from\n","        \"\"\"\n","        dataset = []\n"," \n","        dir = \"\"\n","        \n","        if file is None:\n","          if dev:\n","              dir = datapath + 'cloze_test.csv'\n","          else:\n","              dir = datapath + 'cloze_train.csv'\n","        else: dir = datapath + file\n","\n","        # if dev=True, we load the dev set for testing\n","        with open(dir, 'r', encoding='utf-8') as d:\n","            reader = csv.reader(d, quotechar='\"', delimiter=',', \n","                                quoting=csv.QUOTE_ALL, skipinitialspace=True)                \n","            for line in reader:\n","                dataset.append(line) \n","            dataset.pop(0)\n"," \n","        self.data = []\n","        self.labels = []\n"," \n","        for sample in dataset:\n","            \n","            start = \" \".join(sample[1:-3])\n","            if hypothesis_only: start = \"\"\n","            end1 = sample[-3]\n","            end2 = sample[-2]\n","            right_ending = sample[-1]\n"," \n","            self.data.append([start, end1, end2])\n","            self.labels.append(0 if \"1\" == right_ending else 1)\n"," \n","    def __getitem__(self, idx):\n","        X = self.data[idx]\n","        y = self.labels[idx]        \n","        return X, y\n"," \n","    def __len__(self):\n","        assert len(self.data) == len(self.labels)\n","        return len(self.labels)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l5vXXr3pOpwh"},"source":["# Auxiliary Functions"]},{"cell_type":"code","metadata":{"id":"dw0X81uWJVwd","executionInfo":{"status":"ok","timestamp":1617103774701,"user_tz":-120,"elapsed":744,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["def getModelFileName(model_name, last_epoch):\n","    return modelpath + model_name + str(last_epoch)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgItyJtueXHR","executionInfo":{"status":"ok","timestamp":1617103774701,"user_tz":-120,"elapsed":744,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["def weight_diff(model1, model2):\n","    diff = torch.nn.MSELoss() # diff(a, b) = ((a - b) ** 2).mean()\n","\n","    xweights, yweights, xbiases, ybiases = dict(), dict(), dict(), dict()\n","    layer_names = set()\n","\n","    for (name, parameter1), parameter2 in zip(\n","        model1.bert.encoder.layer.named_parameters(),\n","        model2.bert.encoder.layer.parameters()\n","    ):\n","\n","        difference = diff(parameter1, parameter2).item()\n","\n","        name = name.split(\".\")\n","        xtick = float(name[0])\n","        layer_name = \".\".join(name[1:-1])\n","        parameter_type = name[-1]\n","\n","        if layer_name not in layer_names:\n","            layer_names.add(layer_name)\n","            xweights[layer_name], xbiases[layer_name] = list(), list()\n","            yweights[layer_name], ybiases[layer_name] = list(), list()\n","\n","        if parameter_type == \"weight\":\n","            yweights[layer_name].append(difference)\n","            xweights[layer_name].append(xtick + 0.0)\n","        else: # if parameter_type == \"bias\"\n","            ybiases[layer_name].append(difference)\n","            xbiases[layer_name].append(xtick + 0.5)\n","\n","    for name in layer_names:\n","        plt.bar(xweights[name], yweights[name], width=0.4, label=\"weight\")\n","        plt.bar(xbiases[name], ybiases[name], width=0.4, label=\"bias\")\n","        plt.xticks(xweights[name])\n","        plt.legend()\n","        plt.title(name)\n","        plt.show()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PECOGcFZOx5h"},"source":["# Functions for Training and Testing"]},{"cell_type":"code","metadata":{"id":"_yCLlZ7UPpfa","executionInfo":{"status":"ok","timestamp":1617103776518,"user_tz":-120,"elapsed":618,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["def train(cloze_test, model_file=BASE_MODEL, batch_size=BATCH_SIZE,\n","          warmup_epochs=WARMUP_EPOCHS, train_epochs=TRAIN_EPOCHS,\n","          last_epoch=LAST_EPOCH, verbose=False, model_name=None):\n","    \"\"\"\n","    Train model with loss based on binary testing\n","\n","    :param cloze_test: Boolean. If true, train on story cloze test training set. If false, train on RocStories training set\n","    :param model_file: Model file to be finetuned\n","    :param model_name: Filename for saving the trained model\n","    \"\"\"\n","\n","    tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n","    model = BertForNextSentencePrediction.from_pretrained(model_file)\n","    # The old weights are saved in model_old to be used to compare to model\n","    model_old = BertForNextSentencePrediction.from_pretrained(model_file)\n","\n","    #Send to GPU and allow Training\n","    model = model.to(device)\n","    model.train()\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        ClozeTest(dev=False) if cloze_test else RocStories(),\n","        batch_size=batch_size, shuffle=True\n","    )\n","\n","    #LR maybe needs to be optimized\n","    optimizer = AdamW(model.parameters(), lr=1e-5)\n","    n_batches =  len(trainloader)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=(warmup_epochs * n_batches),\n","        num_training_steps=(train_epochs * n_batches),\n","        last_epoch=max(-1, last_epoch * n_batches) # actually, last_step\n","    )\n","    losses = []\n","\n","    epochs_range = range(last_epoch + 1, train_epochs)\n","    for epoch in tqdm(epochs_range):\n","        \n","        for batchId, (stories, labels) in zip(range(n_batches), trainloader):\n","            # this is PyTorch-specific as gradients get accumulated        \n","            optimizer.zero_grad()\n","\n","            start = stories[0]\n","            end = stories[1]\n","\n","            labels = labels.to(device)\n","           \n","            # Tokenize sentence pairs.\n","            # All sequences in batch processing must be same length.\n","            # Therefore we use padding to fill shorter sequences\n","            # with uninterpreted [PAD] tokens)\n","            tokenized_batch = tokenizer(start, padding = True, text_pair = end,\n","                                        return_tensors='pt').to(device)\n","            \n","            loss = model(**tokenized_batch, labels = labels).loss\n","            if verbose:\n","                print(\"Epoch \" + str(epoch + 1) + \n","                      \" Batch \" + batchId + \" of \" + n_batches + \n","                      \" Loss: \" + loss.item())\n","            losses.append(loss.item())\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step() # Huggingface specific: step = epoch\n","\n","        model.save_pretrained(\n","            getModelFileName(model_name, epoch + 1)\n","        )\n","    \n","    # Loss function change over steps is plotted below.\n","    plt.plot(losses)\n","    plt.xticks(\n","        ticks=[(i - last_epoch - 1) * n_batches for i in epochs_range],\n","        labels=epochs_range\n","    )\n","    plt.title((\"Story Cloze\" if cloze_test else \"ROCStories\") + \" Training\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    # Models are compared\n","    weight_diff(model, model_old)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypcXSNFzu0Ds","executionInfo":{"status":"ok","timestamp":1617103777639,"user_tz":-120,"elapsed":1737,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["def test(model_file=BASE_MODEL, verbose = False, cloze_test = ClozeTest()):\n","    \"\"\"\n","    Test model in binary testing mode.\n","\n","    :param cloze_test: Torch dataset used for testing\n","    :param model_file: File of model to be tested\n","    \"\"\"\n","    softmax = torch.nn.Softmax(dim=1)\n","    tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n","    model = BertForNextSentencePrediction.from_pretrained(model_file)\n","\n","    #Send to GPU and allow Evaluation\n","    model = model.to(device)\n","    model.eval()\n","\n","    #Dataloader\n","    devloader = torch.utils.data.DataLoader(cloze_test, batch_size=10)\n","\n","    pred_list, label_list = list(), list()\n","\n","    for stories, labels in tqdm(devloader, disable=verbose):\n","        \n","        start = stories[0]\n","        end = stories[1]\n","        \n","        # Tokenize sentence pairs.\n","        # All sequences in batch processing must be same length.\n","        # Therefore we use padding to fill shorter sequences\n","        # with uninterpreted [PAD] tokens)\n","        tokenized_batch = tokenizer(start, padding = True, text_pair = end,\n","                                    return_tensors='pt').to(device)\n","\n","        #Send to GPU\n","        labels = labels.to(device)\n","\n","        outputs = model(**tokenized_batch, labels = labels)\n","        logits = outputs.logits\n","\n","        # Model predicts sentence-pair as correct if True-logit > False-logit\n","        predictions = logits.argmax(dim=1).int()\n","        probs = softmax(logits).cpu().detach()\n","\n","        # Extra info print() if verbose\n","        if verbose:\n","            # iterate over elements in batch\n","            for i, element_input_ids in enumerate(tokenized_batch.input_ids):\n","                print(tokenizer.decode(element_input_ids))\n","                print(\"Probability:\", probs[i][0].item() * 100)\n","                print(\"Predicted: \", bool(predictions[i]))\n","                print(\"True label: \", bool(labels[i]))\n","\n","        pred_list.extend(predictions.tolist())\n","        label_list.extend(labels.tolist())\n","\n","    #print(confusion_matrix(label_list, pred_list))\n","    print(classification_report(label_list, pred_list))\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSMuVmylKNvD","executionInfo":{"status":"ok","timestamp":1617103777936,"user_tz":-120,"elapsed":2032,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["def train_MC(cloze_test = ClozeTest_MC(dev=False), model_file=BASE_MODEL, batch_size=BATCH_SIZE,\n","          warmup_epochs=WARMUP_EPOCHS, train_epochs=TRAIN_EPOCHS,\n","          last_epoch=LAST_EPOCH, verbose=False, model_name=None):\n","    \n","    \"\"\"\n","    Train model with loss based on choice testing\n","    \n","    :param cloze_test: Boolean. If true, train on story cloze test training set. If false, train on RocStories training set\n","    :param model_file: Model file to be finetuned\n","    :param model_name: Filename for saving the trained model\n","    \"\"\"\n","    \n","    tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n","    model = BertForNextSentencePrediction.from_pretrained(model_file)\n","    # The old weights are saved in model_old to be used to compare to model\n","    model_old = BertForNextSentencePrediction.from_pretrained(model_file)\n","\n","    #Send to GPU and allow Training\n","    model = model.to(device)\n","    model.train()\n","\n","    trainloader = torch.utils.data.DataLoader(cloze_test, batch_size=batch_size, shuffle=True)\n","\n","    #LR maybe needs to be optimized\n","    optimizer = AdamW(model.parameters(), lr=1e-5)\n","    n_batches =  len(trainloader)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=(warmup_epochs * n_batches),\n","        num_training_steps=(train_epochs * n_batches),\n","        last_epoch=max(-1, last_epoch * n_batches) # actually, last_step\n","    )\n","    \n","    loss_fct = torch.nn.CrossEntropyLoss()\n","\n","    losses = []\n","    epochs_range = range(last_epoch + 1, train_epochs)\n","    for epoch in tqdm(epochs_range):\n","        \n","        for batchId, (stories, labels) in zip(range(n_batches), trainloader):\n","            # this is PyTorch-specific as gradients get accumulated        \n","            optimizer.zero_grad()\n","\n","            start = stories[0]\n","            end1 = stories[1]\n","            end2 = stories[2]\n","\n","            tokenized_batch_end1 = tokenizer(start, padding = True, text_pair = end1,\n","                                        return_tensors='pt').to(device)\n","            \n","            tokenized_batch_end2 = tokenizer(start, padding = True, text_pair = end2,\n","                                        return_tensors='pt').to(device) \n","    \n","            #Send to GPU\n","            labels = labels.to(device)\n","    \n","            \n","            logits0 = model(**tokenized_batch_end1).logits\n","            logits1 = model(**tokenized_batch_end2).logits    \n","\n","            logits_combined = logits0 + logits1.flip(-1)\n","            loss = loss_fct(logits_combined.view(-1,2), labels.view(-1))\n","            losses.append(loss.item())\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step() # Huggingface specific: step = epoch\n","\n","        model.save_pretrained(\n","            getModelFileName(model_name, epoch + 1)\n","        )\n","    \n","    # Loss function change over steps is plotted below.\n","    plt.plot(losses)\n","    plt.xticks(\n","        ticks=[(i - last_epoch - 1) * n_batches for i in epochs_range],\n","        labels=epochs_range\n","    )\n","    plt.title((\"Story Cloze\" if cloze_test else \"ROCStories\") + \" Training\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    # Models are compared\n","    weight_diff(model, model_old)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXZqHmtHZLxC","executionInfo":{"status":"ok","timestamp":1617103778133,"user_tz":-120,"elapsed":2228,"user":{"displayName":"Johannes Eschbach","photoUrl":"","userId":"07016017118869064956"}}},"source":["def test_MC(model_file=BASE_MODEL, verbose = False, cloze_test = ClozeTest_MC(dev=True)):       \n","    \"\"\"\n","    Test model in choice based testing mode.\n","\n","    :param cloze_test: Torch dataset used for testing\n","    :param model_file: File of model to be tested\n","    \"\"\"\n","\n","    softmax = torch.nn.Softmax(dim=1)\n","    tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n","    model = BertForNextSentencePrediction.from_pretrained(model_file)\n"," \n","    #Send to GPU and allow Evaluation\n","    model = model.to(device)\n","    model.eval()\n"," \n","    #Dataloader\n","    devloader = torch.utils.data.DataLoader(cloze_test, batch_size=10)\n"," \n","    pred_list, label_list = list(), list()\n"," \n","    for stories, labels in tqdm(devloader, disable=verbose):\n","        \n","        start = stories[0]\n","        end1 = stories[1]\n","        end2 = stories[2]\n"," \n","        tokenized_batch_end1 = tokenizer(start, padding = True, text_pair = end1,\n","                                    return_tensors='pt').to(device)\n","        \n","        tokenized_batch_end2 = tokenizer(start, padding = True, text_pair = end2,\n","                                    return_tensors='pt').to(device) \n"," \n","        #Send to GPU\n","        labels = labels.to(device)       \n","        \n","        logits0 = model(**tokenized_batch_end1).logits\n","        logits1 = model(**tokenized_batch_end2).logits    \n","\n","        logits = logits0 + logits1.flip(-1)\n","        \n","        predictions = logits.argmax(dim=1).int()\n","        probs = softmax(logits).cpu().detach()        \n","        \n","\n","        # Extra info print() if verbose\n","        if verbose:\n","            # iterate over elements in batch\n","            for i, element_input_ids in enumerate(tokenized_batch.input_ids):\n","                print(tokenizer.decode(element_input_ids))\n","                print(\"Probability:\", probs[i][0].item() * 100)\n","                print(\"Predicted: \", bool(predictions[i]))\n","                print(\"True label: \", bool(labels[i]))\n"," \n","        pred_list.extend(predictions.tolist())\n","        label_list.extend(labels.tolist())\n"," \n","    #print(confusion_matrix(label_list, pred_list))\n","\n","    print(classification_report(label_list, pred_list))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"OE13bxsw9zSz"},"source":["def train_mixed(model_file=BASE_MODEL, batch_size=BATCH_SIZE,\n","          warmup_epochs=WARMUP_EPOCHS, train_epochs=TRAIN_EPOCHS,\n","          last_epoch=LAST_EPOCH, verbose=False, model_name=None):\n","    \"\"\"\n","    Train model with loss based on binary testing. Merges ClozeTest and 5000 ROCStories for training.\n","    \n","    :param cloze_test: Boolean. If true, train on story cloze test training set. If false, train on RocStories training set\n","    :param model_file: Model file to be finetuned\n","    :param model_name: Filename for saving the trained model\n","    \"\"\"\n","\n","    tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n","    model = BertForNextSentencePrediction.from_pretrained(model_file)\n","    # The old weights are saved in model_old to be used to compare to model\n","    model_old = BertForNextSentencePrediction.from_pretrained(model_file)\n","\n","    #Send to GPU and allow Training\n","    model = model.to(device)\n","    model.train()\n","\n","    cloze = ClozeTest(dev=False)\n","    roc = RocStories(short = True)\n","    cloze.data.extend(roc.data)\n","    cloze.labels.extend(roc.labels)\n","\n","\n","    trainloader = torch.utils.data.DataLoader(cloze, batch_size=batch_size, shuffle=True)\n","\n","\n","    #LR maybe needs to be optimized\n","    optimizer = AdamW(model.parameters(), lr=1e-5)\n","    n_batches =  len(trainloader)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=(warmup_epochs * n_batches),\n","        num_training_steps=(train_epochs * n_batches),\n","        last_epoch=max(-1, last_epoch * n_batches) # actually, last_step\n","    )\n","    losses = []\n","\n","    epochs_range = range(last_epoch + 1, train_epochs)\n","    for epoch in tqdm(epochs_range):\n","        \n","        for batchId, (stories, labels) in zip(range(n_batches), trainloader):\n","            # this is PyTorch-specific as gradients get accumulated        \n","            optimizer.zero_grad()\n","\n","            start = stories[0]\n","            end = stories[1]\n","\n","            labels = labels.to(device)\n","           \n","            # Tokenize sentence pairs.\n","            # All sequences in batch processing must be same length.\n","            # Therefore we use padding to fill shorter sequences\n","            # with uninterpreted [PAD] tokens)\n","            tokenized_batch = tokenizer(start, padding = True, text_pair = end,\n","                                        return_tensors='pt').to(device)\n","            \n","            loss = model(**tokenized_batch, labels = labels).loss\n","            if verbose:\n","                print(\"Epoch \" + str(epoch + 1) + \n","                      \" Batch \" + batchId + \" of \" + n_batches + \n","                      \" Loss: \" + loss.item())\n","            losses.append(loss.item())\n","\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step() # Huggingface specific: step = epoch\n","\n","        model.save_pretrained(\n","            getModelFileName(model_name, epoch + 1)\n","        )\n","    \n","    # Loss function change over steps is plotted below.\n","    plt.plot(losses)\n","    plt.xticks(\n","        ticks=[(i - last_epoch - 1) * n_batches for i in epochs_range],\n","        labels=epochs_range\n","    )\n","    plt.title((\"Story Cloze\" if cloze_test else \"ROCStories\") + \" Training\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    # Models are compared\n","    weight_diff(model, model_old)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwY6i_K19TBz"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"SXgTW9ZGIshN"},"source":["## RocOnly "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_epochs_roc = 2\n","train(train_epochs=train_epochs_roc, cloze_test=False, batch_size=32, warmup_epochs=0, model_name=ROC_MODEL)\n","test(getModelFileName(ROC_MODEL, train_epochs_roc))"]},{"cell_type":"markdown","metadata":{"id":"2EDcfMlhItBd"},"source":["## ClozeOnly"]},{"cell_type":"code","metadata":{"id":"uWa6H3k_ItMV"},"source":["train_epochs_cloze = 10\n","train(train_epochs = train_epochs_cloze, cloze_test=True, model_name=\"bertfornsp_clozeonly_finetuned\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x1-E16-F984x"},"source":["## Cloze + 5000Roc"]},{"cell_type":"code","metadata":{"id":"V791c8tC-Az6"},"source":["train_epochs_cloze = 5\n","train_mixed(model_name = \"bertfornsp_mixed_more_roc\", train_epochs = train_epochs_cloze)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7tMGx20xnPC5"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"9fHALGMn6EkP"},"source":["def test_testset(file, hypothesis_only):\n","    \"\"\"\n","    All models are tested in both test setups (binary and choice) on a testset\n","    \n","    :param file: The csv file of the dataset to be tested\n","    :hypothesis_only: If true, models are tested with hypothesis only\n","    \"\"\"\n","    cloze_test = ClozeTest(dev=True, hypothesis_only = hypothesis_only, file=file)\n","    cloze_test_mc = ClozeTest_MC(dev=True, hypothesis_only=hypothesis_only, file=file)\n","    \n","\n","    print(\"\\nBert\\n\")\n","    test(BASE_MODEL, cloze_test = cloze_test)\n","    test_MC(BASE_MODEL, cloze_test = cloze_test_mc)\n","\n","    print(\"\\nRocOnly\\n\")\n","    test(getModelFileName(ROC_MODEL, \"\"), cloze_test = cloze_test)\n","    test_MC(getModelFileName(ROC_MODEL, \"\"), cloze_test = cloze_test_mc)\n","\n","    print(\"\\nClozeOnly\\n\")\n","    test(getModelFileName(\"bertfornsp_clozeonly_finetuned\", \"10\"), cloze_test = cloze_test)\n","    test_MC(getModelFileName(\"bertfornsp_clozeonly_finetuned\", \"10\"), cloze_test = cloze_test_mc)\n","\n","    print(\"\\nRocCloze\\n\")\n","    test(getModelFileName(\"bertfornsp_cloze_finetuned\", \"10\"), cloze_test = cloze_test)\n","    test_MC(getModelFileName(\"bertfornsp_cloze_finetuned\", \"10\"), cloze_test = cloze_test_mc)\n","\n","    print(\"\\nCloze + 5000 Roc\\n\")\n","    test(getModelFileName(\"bertfornsp_mixed\", \"5\"), cloze_test = cloze_test)\n","    test_MC(getModelFileName(\"bertfornsp_mixed\", \"5\"), cloze_test = cloze_test_mc)"],"execution_count":null,"outputs":[]}]}