{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"synon_truncateTriggers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/JohannesEschbach/BERT_ROC/blob/kamal/synon_truncateTriggers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-iZVPOFa_Tp","executionInfo":{"status":"ok","timestamp":1617156414198,"user_tz":-120,"elapsed":3659,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}},"outputId":"d34c2b7a-22df-48e5-daae-5d199d84dc00"},"source":["!pip install transformers"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o27YmkbJa_wt","executionInfo":{"status":"ok","timestamp":1617156415541,"user_tz":-120,"elapsed":4996,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}},"outputId":"4ceec791-ab21-484c-b9b7-b8f93253d029"},"source":["from google.colab import drive\n","\n","current_directory = '/content/drive/MyDrive/FSem/'\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UZtXKD8RKkXs"},"source":["# Removal filters"]},{"cell_type":"code","metadata":{"id":"SO2MqVIXs-Ko","executionInfo":{"status":"ok","timestamp":1617156415727,"user_tz":-120,"elapsed":5177,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}}},"source":["def instead_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"instead\":\n","            if i + 1 < len(tokens) and tokens[i + 1] == \"of\":\n","                pass\n","            else:\n","                tokens.pop(i)\n","                changed = True\n","                i = i - 1\n","        i = i + 1\n","    return changed\n","\n","def ever_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"ever\":\n","            if i > 0 and tokens[i - 1] == \"than\":\n","                pass\n","            else:\n","                tokens.pop(i)\n","                changed = True\n","                i = i - 1\n","        i = i + 1\n","    return changed\n","\n","def anymore_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"anymore\":\n","            tokens.pop(i)\n","            changed = True\n","            i = i - 1\n","        i = i + 1\n","    return changed\n","\n","def too_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"too\" and i + 1 < len(tokens) and tokens[i + 1] == \".\":\n","            tokens.pop(i)\n","            i = i - 1\n","            if i >= 0 and tokens[i] == \",\":\n","                tokens.pop(i)\n","                i = i - 1\n","            changed = True\n","        i = i + 1\n","    return changed\n","\n","def eventually_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"eventually\":\n","            tokens.pop(i)\n","            if i < len(tokens) and tokens[i] == \",\":\n","                tokens.pop(i)\n","            i = i - 1\n","            changed = True\n","        i = i + 1\n","    return changed\n","\n","def immediately_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"immediately\":\n","            tokens.pop(i)\n","            i = i - 1\n","            changed = True\n","        i = i + 1\n","    return changed\n","\n","def anyway_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"anyway\":\n","            tokens.pop(i)\n","            i = i - 1\n","            changed = True\n","        i = i + 1\n","    return changed\n","\n","def soon_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"soon\":\n","            if i > 0 and tokens[i - 1] == \"as\":\n","                pass\n","            else:\n","                tokens.pop(i)\n","                if i < len(tokens) and tokens[i] == \",\":\n","                    tokens.pop(i)\n","                i = i - 1\n","                changed = True\n","        i = i + 1\n","    return changed\n","\n","def later_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"later\":\n","            if i > 3 and tokens[i - 4] == \"two\" and tokens[i - 3] == \"mile\" and tokens[i - 2] == \"##s\" and tokens[i - 1] == \"half\":\n","                pass\n","            elif i > 1 and tokens[i - 2] == \"month\" and tokens[i - 1] == \"##s\":\n","                pass\n","            elif i > 1 and tokens[i - 2] == \"week\" and tokens[i - 1] == \"##s\":\n","                pass\n","            elif i > 1 and tokens[i - 2] == \"day\" and tokens[i - 1] == \"##s\":\n","                pass\n","            elif i > 0 and tokens[i - 1] == \"year\":\n","                pass\n","            else:\n","                tokens.pop(i)\n","                if i + 1 < len(tokens) and tokens[i] == \"on\" and tokens[i + 1] == \",\":\n","                    tokens.pop(i)\n","                    tokens.pop(i)\n","                elif i < len(tokens) and tokens[i] == \",\":\n","                    tokens.pop(i)\n","                elif i + 1 < len(tokens) and tokens[i] == \"that\" and tokens[i + 1] == \"day\":\n","                    tokens.pop(i)\n","                    tokens.pop(i)\n","                elif i + 2 < len(tokens) and tokens[i] == \"in\" and tokens[i + 1] == \"his\" and tokens[i + 2] == \"life\":\n","                    tokens.pop(i)\n","                    tokens.pop(i)\n","                    tokens.pop(i)\n","                i = i - 1\n","                changed = True\n","        i = i + 1\n","    return changed\n","\n","def now_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"now\":\n","            if i + 1 < len(tokens):\n","                if tokens[i + 1] == \",\":\n","                    tokens.pop(i)\n","                    tokens.pop(i)\n","                    changed = True\n","                    i = i - 1\n","                elif tokens[i + 1] == \".\":\n","                    tokens.pop(i)\n","                    changed = True\n","                    i = i - 1\n","        i = i + 1\n","    return changed\n","\n","def finally_filter(tokens):\n","    changed = False\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"finally\":\n","            tokens.pop(i)\n","            changed = True\n","            if i < len(tokens) and tokens[i] == \",\":\n","                tokens.pop(i)\n","            i = i - 1\n","        i = i + 1\n","    return changed\n","\n","filters = [instead_filter, ever_filter, anymore_filter, too_filter, eventually_filter, immediately_filter, anyway_filter, soon_filter, later_filter, now_filter, finally_filter]\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UE35xvB50Mfr"},"source":["# Synonymizers"]},{"cell_type":"code","metadata":{"id":"NR4WfeSi0Lj1","executionInfo":{"status":"ok","timestamp":1617156415925,"user_tz":-120,"elapsed":5372,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}}},"source":["def instead_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"instead\":\n","            if i + 1 < len(tokens) and tokens[i + 1] == \"of\":\n","                pass\n","            else:\n","                tokens[i] = \"alternatively\"\n","        i = i + 1\n","\n","def ever_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"ever\":\n","            if i > 0 and tokens[i - 1] == \"than\":\n","                pass\n","            else:\n","                tokens[i] = \"at\"\n","                tokens.insert(i + 1, \"any\")\n","                tokens.insert(i + 2, \"point\")\n","                i = i + 2\n","        i = i + 1\n","\n","def anymore_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"anymore\":\n","            tokens[i] = \"any\"\n","            tokens.insert(i + 1, \"further\")\n","            i = i + 1\n","        i = i + 1\n","\n","def too_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"too\" and i + 1 < len(tokens) and tokens[i + 1] == \".\":\n","            tokens[i] = \"as\"\n","            tokens.insert(i + 1, \"well\")\n","            i = i + 1\n","        i = i + 1\n","\n","def eventually_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"eventually\":\n","            tokens[i] = \"ultimately\"\n","        i = i + 1\n","\n","def immediately_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"immediately\":\n","            tokens[i] = \"instantly\"\n","        i = i + 1\n","\n","def anyway_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"anyway\":\n","            tokens[i] = \"any\"\n","            tokens.insert(i + 1, \"##how\")\n","            i = i + 1\n","        i = i + 1\n","\n","def soon_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"soon\":\n","            if i > 0 and tokens[i - 1] == \"as\":\n","                pass\n","            else:\n","                tokens[i] = \"shortly\"\n","        i = i + 1\n","\n","def later_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"later\":\n","            if i > 3 and tokens[i - 4] == \"two\" and tokens[i - 3] == \"mile\" and tokens[i - 2] == \"##s\" and tokens[i - 1] == \"half\":\n","                pass\n","            elif i > 1 and tokens[i - 2] == \"month\" and tokens[i - 1] == \"##s\":\n","                pass\n","            elif i > 1 and tokens[i - 2] == \"week\" and tokens[i - 1] == \"##s\":\n","                pass\n","            elif i > 1 and tokens[i - 2] == \"day\" and tokens[i - 1] == \"##s\":\n","                pass\n","            elif i > 0 and tokens[i - 1] == \"year\":\n","                pass\n","            else:\n","                # no adequate synonyms, handled manually\n","                tokens[i] = \"afterwards\"\n","                if i + 1 < len(tokens) and tokens[i + 1] == \"on\" and tokens[i + 2] == \",\":\n","                    tokens.pop(i + 1)\n","                    tokens.pop(i + 1)\n","        i = i + 1\n","\n","def now_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"now\":\n","            if i + 1 < len(tokens):\n","                tokens[i] = \"currently\"\n","        i = i + 1\n","\n","def finally_synonymizer(tokens):\n","    i = 0\n","    while i < len(tokens):\n","        if tokens[i] == \"finally\":\n","            tokens[i] = \"at\"\n","            tokens.insert(i + 1, \"last\")\n","            i = i + 1\n","        i = i + 1\n","\n","synonymizers = [instead_synonymizer, ever_synonymizer, anymore_synonymizer, too_synonymizer, eventually_synonymizer, immediately_synonymizer, anyway_synonymizer, soon_synonymizer, later_synonymizer, now_synonymizer, finally_synonymizer]\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"huFR1hQ5tEKG"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"7TlyrYG-tFZ1","executionInfo":{"status":"ok","timestamp":1617156416402,"user_tz":-120,"elapsed":5846,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}}},"source":["from transformers import BertTokenizer\n","import csv\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n","\n","source_file = open(current_directory + 'cloze_test.csv', 'r', encoding='utf-8')\n","source_reader = csv.reader(source_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n","\n","triggers_removed_file = open(current_directory + 'cloze_test_triggers_removed.csv', 'w', encoding='utf-8')\n","triggers_synonymized_file = open(current_directory + 'cloze_test_triggers_synonymized.csv', 'w', encoding='utf-8')\n","triggers_only_file = open(current_directory + 'cloze_test_triggers_only.csv', 'w', encoding='utf-8')\n","triggers_removed_only_file = open(current_directory + 'cloze_test_triggers_removed_only.csv', 'w', encoding='utf-8')\n","triggers_synonymized_only_file = open(current_directory + 'cloze_test_triggers_synonymized_only.csv', 'w', encoding='utf-8')\n","\n","triggers_removed_writer = csv.writer(triggers_removed_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n","triggers_synonymized_writer = csv.writer(triggers_synonymized_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n","triggers_only_writer = csv.writer(triggers_only_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n","triggers_removed_only_writer = csv.writer(triggers_removed_only_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n","triggers_synonymized_only_writer = csv.writer(triggers_synonymized_only_file, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJYpVfLq0ZNg","executionInfo":{"status":"ok","timestamp":1617156416403,"user_tz":-120,"elapsed":5844,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}}},"source":["source_lines = []\n","\n","for source_line in source_reader:\n","  source_lines.append(source_line)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eWG1WwmK1I-T","executionInfo":{"status":"ok","timestamp":1617156416404,"user_tz":-120,"elapsed":5841,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}},"outputId":"fabb7224-399c-4281-a4ec-228e9a7be55c"},"source":["triggers_removed_writer.writerow(source_lines[0])\n","triggers_synonymized_writer.writerow(source_lines[0])\n","triggers_only_writer.writerow(source_lines[0])\n","triggers_removed_only_writer.writerow(source_lines[0])\n","triggers_synonymized_only_writer.writerow(source_lines[0])\n","\n","source_lines.pop(0)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['InputStoryid',\n"," 'InputSentence1',\n"," 'InputSentence2',\n"," 'InputSentence3',\n"," 'InputSentence4',\n"," 'RandomFifthSentenceQuiz1',\n"," 'RandomFifthSentenceQuiz2',\n"," 'AnswerRightEnding']"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"BUOVrQ9xcRTV"},"source":["# Modification"]},{"cell_type":"code","metadata":{"id":"Rdbaq9zOcegs","executionInfo":{"status":"ok","timestamp":1617156417529,"user_tz":-120,"elapsed":6961,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}}},"source":["for source_line in source_lines:\n","    changed = False\n","    tokens1_to_remove = tokenizer.tokenize(source_line[-3])\n","    tokens1_to_synonymize = tokens1_to_remove.copy()\n","    tokens2_to_remove = tokenizer.tokenize(source_line[-2])\n","    tokens2_to_synonymize = tokens2_to_remove.copy()\n","\n","    for filter, synonymizer in zip(filters, synonymizers):\n","        changed = changed or filter(tokens1_to_remove) or filter(tokens2_to_remove)\n","        synonymizer(tokens1_to_synonymize)\n","        synonymizer(tokens2_to_synonymize)\n","\n","    sentence1_triggers_removed = tokenizer.convert_tokens_to_string(tokens1_to_remove)\n","    sentence2_triggers_removed = tokenizer.convert_tokens_to_string(tokens2_to_remove)\n","    triggers_removed_line = source_line[:-3] + [sentence1_triggers_removed] + [sentence2_triggers_removed] + source_line[-1:]\n","    triggers_removed_writer.writerow(triggers_removed_line)\n","\n","    sentence1_triggers_synonymized = tokenizer.convert_tokens_to_string(tokens1_to_synonymize)\n","    sentence2_triggers_synonymized = tokenizer.convert_tokens_to_string(tokens2_to_synonymize)\n","    triggers_synonymized_line = source_line[:-3] + [sentence1_triggers_synonymized] + [sentence2_triggers_synonymized] + source_line[-1:]\n","    triggers_synonymized_writer.writerow(triggers_synonymized_line)\n","\n","    if changed:\n","        triggers_only_writer.writerow(source_line)\n","        triggers_removed_only_writer.writerow(triggers_removed_line)\n","        triggers_synonymized_only_writer.writerow(triggers_synonymized_line)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UURQLBCWjL_I"},"source":["# Wrap-up"]},{"cell_type":"code","metadata":{"id":"Q_Igrl1ajOfe","executionInfo":{"status":"ok","timestamp":1617156417531,"user_tz":-120,"elapsed":6956,"user":{"displayName":"Kamal Eyubov","photoUrl":"","userId":"01640215455946508583"}}},"source":["source_file.close()\n","triggers_removed_file.close()\n","triggers_synonymized_file.close()\n","triggers_only_file.close()\n","triggers_removed_only_file.close()\n","triggers_synonymized_only_file.close()"],"execution_count":19,"outputs":[]}]}